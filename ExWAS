#!/usr/bin/env python3
"""
ukb_wes_exwas_vig_vs_sed.py
===========================

UK Biobank OQFE WES **Exome-Wide Association Study (ExWAS)** helper that models
**vigorous activity vs sedentary activity**.

What it does
------------
1) Builds a PLINK/REGENIE-ready `.phe`:
   - Reads participant CSV/Parquet with EID + activity + covariates
   - Optionally derives season/quarter from a date column
   - Transforms TWO activity columns independently:
       * outcome (phenotype): e.g., vigorous_activity
       * adjuster (covariate): e.g., sedentary_activity
     Each can be normalized to [0,1] and optionally inverted.
   - Harmonizes with WES `.fam`
   - Writes `.phe` with both transformed columns

2) Runs ExWAS (optional):
   - PLINK 2 (`--glm`)
   - REGENIE step 1 (array) + step 2 (exome), quantitative by default

Usage examples
--------------
# Vigorous as outcome, adjust for sedentary (both normalized; vigorous inverted)
python ukb_wes_exwas_vig_vs_sed.py \
  --source accel_covariates.csv \
  --fam ukb23158_c1_b0_v1.fam \
  --eid-col eid \
  --phenotype-col vigorous_activity --phenotype-invert \
  --adjust-col sedentary_activity \
  --covars-base 31,21022,22009_1,22009_2,22009_3,22009_4,22009_5 \
  --phe-out pa_wes_vig_vs_sed.phe \
  --run-plink2 \
  --wes-prefix /data/ukb23158_c{CHR}_b0_v1 \
  --threads 8

# Sedentary as outcome, adjust for vigorous (no inversion)
python ukb_wes_exwas_vig_vs_sed.py \
  --source accel_covariates.csv \
  --fam ukb23158_c1_b0_v1.fam \
  --eid-col eid \
  --phenotype-col sedentary_activity \
  --adjust-col vigorous_activity \
  --covars-base 31,21022,22009_1,22009_2,22009_3,22009_4,22009_5 \
  --phe-out pa_wes_sed_vs_vig.phe \
  --run-regenie \
  --array-prefix /data/ukb_array_merged \
  --wes-prefix /data/ukb23158_c{CHR}_b0_v1 \
  --threads 8
"""

import os
import argparse
import subprocess
import pandas as pd
import numpy as np

# ---------- helpers ----------

def read_fam(fam_path: str) -> pd.DataFrame:
    fam_cols = ["FID","IID","PID","MID","SEX","PHENOTYPE"]
    return pd.read_csv(fam_path, sep=r"\s+", header=None, names=fam_cols)

def derive_quarter(df: pd.DataFrame, date_col: str|None) -> pd.DataFrame:
    if date_col and date_col in df.columns:
        df["_date_tmp"] = pd.to_datetime(df[date_col], errors="coerce")
        df["wear_quarter"] = df["_date_tmp"].dt.quarter
        df.drop(columns=["_date_tmp"], inplace=True)
    return df

def normalize_series(s: pd.Series) -> pd.Series:
    s = pd.to_numeric(s, errors="coerce")
    mn, mx = s.min(skipna=True), s.max(skipna=True)
    if pd.isna(mn) or pd.isna(mx) or mx == mn:
        return pd.Series(np.nan, index=s.index)
    return (s - mn) / (mx - mn)

def transform_trait(df: pd.DataFrame, col: str, do_norm: bool, do_inv: bool, label: str) -> tuple[pd.DataFrame,str]:
    """
    Create a transformed column from df[col].
    Returns df and the new column name.
    - If do_norm: new name ends with _norm or _norm_inv
    - If not do_norm and do_inv requested -> error (ambiguous)
    """
    if col not in df.columns:
        raise ValueError(f"Column '{col}' not found.")
    if not do_norm and do_inv:
        raise ValueError(f"--{label}-invert requires --{label}-normalize.")
    if do_norm:
        norm = normalize_series(df[col])
        if do_inv:
            out_col = f"{col}_norm_inv"
            df[out_col] = 1.0 - norm
        else:
            out_col = f"{col}_norm"
            df[out_col] = norm
    else:
        out_col = col
        df[out_col] = pd.to_numeric(df[col], errors="coerce")
    return df, out_col

def harmonize_with_fam(df: pd.DataFrame, fam: pd.DataFrame, eid_col: str) -> pd.DataFrame:
    df[eid_col] = pd.to_numeric(df[eid_col], errors="coerce").astype("Int64")
    fam["IID"] = pd.to_numeric(fam["IID"], errors="coerce").astype("Int64")
    df["FID"] = df[eid_col]
    df["IID"] = df[eid_col]
    merged = fam[["FID","IID"]].merge(
        df.drop(columns=[c for c in ["FID","IID"] if c in df.columns]),
        on="IID", how="inner"
    )
    merged["FID"] = merged["IID"]
    return merged

def write_phe(df: pd.DataFrame, out_path: str) -> None:
    cols = df.columns.tolist()
    front = [c for c in ["FID","IID"] if c in cols]
    rest = [c for c in cols if c not in front]
    df[front+rest].to_csv(out_path, sep="\t", index=False, na_rep="NA")

# ---------- runners ----------

def run_plink2(wes_prefix: str, phe: str, pheno_name: str, covars: list[str], outdir: str, threads: int = 4, chr_list=range(1,23), mac_min: int = 5):
    os.makedirs(outdir, exist_ok=True)
    phe_df = pd.read_csv(phe, sep="\t")
    keep = os.path.join(outdir, "samples.keep")
    phe_df[["FID","IID"]].to_csv(keep, sep=" ", index=False, header=False)
    covar_str = ",".join(covars)
    for chrn in chr_list:
        bfile = wes_prefix.replace("{CHR}", str(chrn))
        outbase = os.path.join(outdir, f"chr{chrn}_{pheno_name}")
        cmd = [
            "plink2",
            "--bfile", bfile,
            "--keep", keep,
            "--pheno", phe, "--pheno-name", pheno_name,
            "--covar", phe, "--covar-name", covar_str,
            "--glm", "hide-covar", "cols=+a1freq,+a1count,+obs,+mac,+ax",
            "--mac", str(mac_min),
            "--threads", str(threads),
            "--out", outbase
        ]
        print("[PLINK2]", " ".join(cmd))
        subprocess.check_call(cmd)

def run_regenie(array_prefix: str, wes_prefix: str, phe: str, pheno_name: str, covars: list[str],
                outdir1: str, outdir2: str, threads: int = 8, bt: int = 0, chr_list=range(1,23), mac_min: int = 5):
    os.makedirs(outdir1, exist_ok=True)
    os.makedirs(outdir2, exist_ok=True)
    phe_df = pd.read_csv(phe, sep="\t")
    keep = os.path.join(outdir1, "samples.keep")
    phe_df[["FID","IID"]].to_csv(keep, sep=" ", index=False, header=False)
    covar_str = ",".join(covars)
    # Step 1
    cmd1 = [
        "regenie","--step","1",
        "--bed",array_prefix,
        "--keep",keep,
        "--phenoFile",phe,"--phenoCol",pheno_name,
        "--covarFile",phe,"--covarColList",covar_str,
        "--bt",str(bt),
        "--bsize","1000","--lowmem",
        "--lowmem-prefix",os.path.join(outdir1,"tmp_chunks"),
        "--threads",str(threads),
        "--out",os.path.join(outdir1,"step1")
    ]
    print("[REGENIE step1]", " ".join(cmd1))
    subprocess.check_call(cmd1)
    pred_list = os.path.join(outdir1,"step1_pred.list")
    if not os.path.exists(pred_list):
        preds = [os.path.join(outdir1,f) for f in sorted(os.listdir(outdir1)) if f.endswith(".pred")]
        with open(pred_list,"w") as fh:
            for p in preds: fh.write(p+"\n")
    # Step 2 per chromosome
    for chrn in chr_list:
        bed_prefix = wes_prefix.replace("{CHR}", str(chrn))
        outbase = os.path.join(outdir2, f"chr{chrn}")
        cmd2 = [
            "regenie","--step","2",
            "--bed",bed_prefix,
            "--keep",keep,
            "--phenoFile",phe,"--phenoCol",pheno_name,
            "--covarFile",phe,"--covarColList",covar_str,
            "--bt",str(bt),
            "--pred",pred_list,
            "--minMAC",str(mac_min),
            "--threads",str(threads),
            "--out",outbase
        ]
        print("[REGENIE step2]", " ".join(cmd2))
        subprocess.check_call(cmd2)

# ---------- CLI ----------

def main():
    ap = argparse.ArgumentParser(description="ExWAS: model vigorous vs sedentary (choose outcome and adjuster).")
    # Prep
    ap.add_argument("--source", required=True, help="CSV or Parquet with EID + activity columns + covariates")
    ap.add_argument("--fam", required=True, help="WES .fam path")
    ap.add_argument("--eid-col", default="eid", help="Participant ID column")
    ap.add_argument("--date-col", default=None, help="Optional date column for wear quarter")
    # outcome
    ap.add_argument("--phenotype-col", required=True, help="Outcome column (e.g., vigorous_activity OR sedentary_activity)")
    ap.add_argument("--phenotype-normalize", action="store_true", default=True, help="Normalize outcome [0,1] (default on)")
    ap.add_argument("--phenotype-no-normalize", dest="phenotype-normalize", action="store_false", help="Disable normalization for outcome")
    ap.add_argument("--phenotype-invert", action="store_true", help="Invert outcome after normalization")
    # adjuster
    ap.add_argument("--adjust-col", required=True, help="Adjust covariate column (the other activity)")
    ap.add_argument("--adjust-normalize", action="store_true", default=True, help="Normalize adjuster [0,1] (default on)")
    ap.add_argument("--adjust-no-normalize", dest="adjust-normalize", action="store_false", help="Disable normalization for adjuster")
    ap.add_argument("--adjust-invert", action="store_true", help="Invert adjuster after normalization")
    # base covars
    ap.add_argument("--covars-base", default="", help="Comma-separated base covariates (e.g., 31,21022,22009_1,...). These will be combined with the transformed adjust column.")
    ap.add_argument("--phe-out", default="pa_wes_vig_vs_sed.phe", help="Output .phe path")
    # Runners
    ap.add_argument("--run-plink2", action="store_true", help="Run PLINK2 ExWAS")
    ap.add_argument("--run-regenie", action="store_true", help="Run REGENIE ExWAS")
    ap.add_argument("--wes-prefix", help="WES PLINK prefix with {CHR} placeholder")
    ap.add_argument("--threads", type=int, default=8)
    # REGENIE specifics
    ap.add_argument("--array-prefix", help="Array PLINK prefix for step 1 (REGENIE)")
    ap.add_argument("--bt", type=int, default=0, help="Binary trait? 1=yes, 0=quantitative (default)")

    args = ap.parse_args()

    # Load table
    if args.source.lower().endswith(".csv"):
        df = pd.read_csv(args.source)
    elif args.source.lower().endswith(".parquet"):
        df = pd.read_parquet(args.source)
    else:
        raise ValueError("--source must be .csv or .parquet")

    df = derive_quarter(df, args.date_col)

    # Transform outcome and adjuster
    df, pheno_col_out = transform_trait(
        df, args.phenotype_col, getattr(args, "phenotype-normalize"), args.phenotype_invert, label="phenotype"
    )
    df, adjust_col_out = transform_trait(
        df, args.adjust_col, getattr(args, "adjust-normalize"), args.adjust_invert, label="adjust"
    )

    # Harmonize & write .phe
    fam = read_fam(args.fam)
    phe_df = harmonize_with_fam(df, fam, eid_col=args.eid_col)
    write_phe(phe_df, args.phe_out)
    print(f"[OK] wrote {args.phe_out}")
    print(f"    Outcome used in GWAS:   {pheno_col_out}")
    print(f"    Adjuster included as covariate: {adjust_col_out}")

    # Build covariate list = base covars + transformed adjust column
    base_covars = [c for c in args.covars_base.split(",") if c.strip()]
    covars_full = base_covars + [adjust_col_out]

    if args.run_plink2:
        if not args.wes_prefix:
            raise ValueError("--run-plink2 requires --wes-prefix")
        run_plink2(
            wes_prefix=args.wes_prefix,
            phe=args.phe_out,
            pheno_name=pheno_col_out,
            covars=covars_full,
            outdir="results/plink2",
            threads=args.threads
        )

    if args.run_regenie:
        missing = [k for k in ["wes_prefix","array_prefix"] if getattr(args, k) in (None, "")]
        if missing:
            raise ValueError("--run-regenie requires --array-prefix and --wes-prefix")
        run_regenie(
            array_prefix=args.array_prefix,
            wes_prefix=args.wes_prefix,
            phe=args.phe_out,
            pheno_name=pheno_col_out,
            covars=covars_full,
            outdir1="results/regenie_step1",
            outdir2="results/regenie_step2_wes",
            threads=args.threads,
            bt=args.bt
        )

if __name__ == "__main__":
    main()
